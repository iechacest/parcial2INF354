# -*- coding: utf-8 -*-
"""ejercicio1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JPLKBxW3Gj_feRDxmzv_2YUDrfkcqeOq
"""

from google.colab import drive
drive.mount('/content/drive')

class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.4):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.learning_rate = learning_rate

        self.weights_input_hidden = [[0.01] * hidden_size for _ in range(input_size)]
        self.bias_hidden = [0.01] * hidden_size

        self.weights_hidden_output = [[0.01] * output_size for _ in range(hidden_size)]
        self.bias_output = [0.01] * output_size

    def sigmoid(self, x):
        return 1 / (1 + (2.718 ** (-x)))

    def sigmoid_derivative(self, x):
        return x * (1 - x)

    def forward(self, X):
        self.hidden_input = [sum([X[i] * self.weights_input_hidden[i][j] for i in range(self.input_size)]) + self.bias_hidden[j] for j in range(self.hidden_size)]
        self.hidden_output = [self.sigmoid(x) for x in self.hidden_input]

        self.final_input = [sum([self.hidden_output[i] * self.weights_hidden_output[i][j] for i in range(self.hidden_size)]) + self.bias_output[j] for j in range(self.output_size)]
        self.final_output = [self.sigmoid(x) for x in self.final_input]

        return self.final_output

    def backward(self, X, y):
        output_delta = [0] * self.output_size

        for i in range(self.output_size):
            output_delta[i] = (self.final_output[i] - y[i]) * self.sigmoid_derivative(self.final_output[i])

        for i in range(self.hidden_size):
            for j in range(self.output_size):
                self.weights_hidden_output[i][j] -= self.learning_rate * self.hidden_output[i] * output_delta[j]

        for i in range(self.output_size):
            self.bias_output[i] -= self.learning_rate * output_delta[i]

        hidden_delta = [0] * self.hidden_size

        for i in range(self.hidden_size):
            hidden_delta[i] = sum([output_delta[j] * self.weights_hidden_output[i][j] for j in range(self.output_size)]) * self.sigmoid_derivative(self.hidden_output[i])

        for i in range(self.input_size):
            for j in range(self.hidden_size):
                self.weights_input_hidden[i][j] -= self.learning_rate * X[i] * hidden_delta[j]

        for i in range(self.hidden_size):
            self.bias_hidden[i] -= self.learning_rate * hidden_delta[i]

    def train(self, X, y, epochs=10000):
        for epoch in range(epochs):
            total_error = 0
            for i in range(len(X)):
                output = self.forward(X[i])
                self.backward(X[i], y[i])

                total_error += sum([(y[i][j] - output[j]) ** 2 for j in range(len(y[i]))])

            if epoch % 1000 == 0:
                print(f"Epoch {epoch}, Error: {total_error / len(X)}")

    def predict(self, X):
        predictions = []
        for i in range(len(X)):
            output = self.forward(X[i])
            predictions.append(output)

        return predictions

def load_csv(file_path):
    with open(file_path, 'r') as f:
        lines = f.readlines()

    data = [line.strip().split(',') for line in lines[1:]]

    return data


def preprocess_data(data):
    X = []
    y = []

    species_map = {'Iris-setosa': [1, 0, 0],
                   'Iris-versicolor': [0, 1, 0],
                   'Iris-virginica': [0, 0, 1]}

    for row in data:
        X.append([float(val) for val in row[:-1]])

        species = row[-1]
        y.append(species_map.get(species, [0, 0, 0]))

    return X, y

file_path = '/content/drive/MyDrive/datos/IRIS.csv'

data = load_csv(file_path)
X, y = preprocess_data(data)

def normalize_data(X):
    max_vals = [max(col) for col in zip(*X)]

    for i in range(len(X)):
        X[i] = [X[i][j] / max_vals[j] for j in range(len(X[i]))]

    return X

X = normalize_data(X)

input_size = len(X[0])
hidden_size = 5
output_size = 3
learning_rate = 0.4

nn = NeuralNetwork(input_size, hidden_size, output_size, learning_rate)

nn.train(X, y, epochs=10000)

predictions = nn.predict(X)

correct = 0
for i in range(len(y)):
    predicted_class = predictions[i].index(max(predictions[i]))
    if predicted_class == y[i].index(1):
        correct += 1

accuracy = correct / len(y) * 100
print(f"Precisi√≥n en el conjunto de entrenamiento: {accuracy}%")